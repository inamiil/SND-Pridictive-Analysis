import pandas as pd
import numpy as np
from db_connect import run_query
from sklearn.model_selection import TimeSeriesSplit, GridSearchCV
from sklearn.metrics import mean_absolute_error, r2_score
from xgboost import XGBRegressor
from sklearn.preprocessing import LabelEncoder
import matplotlib.pyplot as plt
import matplotlib.ticker as ticker

# === Custom Y-Axis Formatter ===
def format_y_axis_as_k_or_m(ax):
    formatter = ticker.FuncFormatter(lambda x, _: f'{x/1_000_000:.1f}M' if x >= 1_000_000 else f'{x/1_000:.0f}K')
    ax.yaxis.set_major_formatter(formatter)

# === Step 1: Load Data ===
query = """
SELECT 
    REGION,
    BRAND,
    YEAR,
    MONTH,
    SUM(NET_SALE_AMOUNT) AS NET_SALE_AMOUNT
FROM FINAL_QUERY
GROUP BY REGION, BRAND, YEAR, MONTH
ORDER BY REGION, BRAND, YEAR, MONTH
"""
raw_df = pd.DataFrame(run_query(query))

# === Step 1.5: Filter to Top 3 Brands per Region ===
top_brands = (
    raw_df.groupby(["REGION", "BRAND"])["NET_SALE_AMOUNT"]
    .sum()
    .reset_index()
    .sort_values(["REGION", "NET_SALE_AMOUNT"], ascending=[True, False])
)
top_3_brands_per_region = top_brands.groupby("REGION").head(3)[["REGION", "BRAND"]]
raw_df = raw_df.merge(top_3_brands_per_region, on=["REGION", "BRAND"])

# === Step 2: Prepare Features ===
def prepare_features(df):
    df["DATE"] = pd.to_datetime(df["YEAR"].astype(str) + "-" + df["MONTH"].astype(str).str.zfill(2) + "-01")
    df = df.sort_values(["REGION", "BRAND", "DATE"])

    df["NET_SALE_AMOUNT"] = pd.to_numeric(df["NET_SALE_AMOUNT"], errors="coerce").fillna(0)
    df.loc[df["NET_SALE_AMOUNT"] < 0, "NET_SALE_AMOUNT"] = 0

    all_dates = pd.date_range("2023-01-01", "2025-12-01", freq="MS")
    full_index = pd.MultiIndex.from_product(
        [df["REGION"].unique(), df["BRAND"].unique(), all_dates],
        names=["REGION", "BRAND", "DATE"]
    )
    df = df.set_index(["REGION", "BRAND", "DATE"]).reindex(full_index, fill_value=0).reset_index()

    df["MONTH_NUM"] = df["DATE"].dt.month
    df["YEAR_NUM"] = df["DATE"].dt.year

    df["LAG_1"] = df.groupby(["REGION", "BRAND"])["NET_SALE_AMOUNT"].shift(1)
    df["LAG_2"] = df.groupby(["REGION", "BRAND"])["NET_SALE_AMOUNT"].shift(2)
    df["LAG_3"] = df.groupby(["REGION", "BRAND"])["NET_SALE_AMOUNT"].shift(3)

    df["ROLLING_MEAN_3"] = df.groupby(["REGION", "BRAND"])["NET_SALE_AMOUNT"].transform(lambda x: x.rolling(3, min_periods=1).mean())
    df["ROLLING_MEAN_6"] = df.groupby(["REGION", "BRAND"])["NET_SALE_AMOUNT"].transform(lambda x: x.rolling(6, min_periods=1).mean())
    df["MONTH_SIN"] = np.sin(2 * np.pi * df["MONTH_NUM"] / 12)
    df["MONTH_COS"] = np.cos(2 * np.pi * df["MONTH_NUM"] / 12)

    q1 = df["NET_SALE_AMOUNT"].quantile(0.01)
    q99 = df["NET_SALE_AMOUNT"].quantile(0.99)
    df["NET_SALE_AMOUNT"] = df["NET_SALE_AMOUNT"].clip(q1, q99)

    df = df.dropna(subset=["LAG_1", "LAG_2", "LAG_3"])
    df["LOG_SALES"] = np.log1p(df["NET_SALE_AMOUNT"])
    df.replace([np.inf, -np.inf], np.nan, inplace=True)
    df.dropna(inplace=True)

    df["BRAND_ENC"] = LabelEncoder().fit_transform(df["BRAND"])  # REGION not encoded anymore

    return df

# === Step 3: Train Model ===
def train_xgboost_model(X_train, y_train):
    param_grid = {
        'n_estimators': [100, 150, 200],
        'max_depth': [3, 5, 7],
        'learning_rate': [0.01, 0.05, 0.1],
        'subsample': [0.8, 1],
        'colsample_bytree': [0.8, 1]
    }

    model = XGBRegressor(random_state=42, eval_metric='mae')
    grid = GridSearchCV(model, param_grid, cv=TimeSeriesSplit(n_splits=3), scoring='neg_mean_absolute_error', n_jobs=-1, verbose=1)
    grid.fit(X_train, y_train)
    return grid.best_estimator_, grid.best_params_

# === Step 4: Region-Wise Training and Evaluation ===
df = prepare_features(raw_df)
features = ["MONTH_NUM", "LAG_1", "LAG_2", "LAG_3", "ROLLING_MEAN_3", "ROLLING_MEAN_6", "BRAND_ENC","MONTH_SIN","MONTH_COS"]

regions = df["REGION"].unique()
region_metrics = {}

for region in regions:
    region_df = df[df["REGION"] == region]

    train = region_df[region_df["YEAR_NUM"] < 2025]
    test = region_df[(region_df["YEAR_NUM"] == 2025) & (region_df["DATE"].dt.month <= 4)]

    X_train = train[features]
    y_train = train["LOG_SALES"]
    X_test = test[features]
    y_test = test["LOG_SALES"]

    best_model, best_params = train_xgboost_model(X_train, y_train)
    test["PREDICTED_SALES"] = np.expm1(best_model.predict(X_test))
    test["ACTUAL_SALES"] = np.expm1(y_test)

    mae = mean_absolute_error(test["ACTUAL_SALES"], test["PREDICTED_SALES"])
    r2 = r2_score(test["ACTUAL_SALES"], test["PREDICTED_SALES"])
    region_metrics[region] = {"MAE": mae, "R2": r2, "Params": best_params}

    # === Plotting Actual vs Predicted ===
    for (region_, brand), grp in test.groupby(["REGION", "BRAND"]):
        plt.figure(figsize=(8, 4))
        plt.plot(grp["DATE"], grp["ACTUAL_SALES"], label="Actual", marker="o")
        plt.plot(grp["DATE"], grp["PREDICTED_SALES"], label="Predicted", marker="x")
        plt.title(f"{region_} - {brand}")
        plt.legend()
        format_y_axis_as_k_or_m(plt.gca())
        plt.tight_layout()
        plt.show()

# === Print Metrics per Region ===
for region, metrics in region_metrics.items():
    print(f"\nRegion: {region}")
    print(f"Best Params: {metrics['Params']}")
    print(f"MAE: {metrics['MAE']:,.2f} | RÂ²: {metrics['R2']:.3f}")
